# â­Â STAR+Â â€”â€¯Trainingâ€‘Free Recommendations with LLM Superâ€‘Powers

Reâ€‘implementation and extension of the DeepMind paper  
[**STAR: A Simple Trainingâ€‘free Approach for Recommendations using Large Language Models**](https://arxiv.org/abs/2410.16458).


**STAR+** preserves STARâ€™s noâ€‘training philosophy while adding:
* userâ€‘persona embeddings  
* fast FAISS neighbour search  
* optional multimodal (image) embeddings  
* adaptive score fusion  
* promptâ€‘engineered LLM ranking


## ğŸ“ŒÂ Highlights
| Feature | What it gives you |
|---------|------------------|
| **Zero training** | Public checkpoints only â€” no gradients, no GPUs burned. |
| **Personaâ€‘aware retrieval** | Longâ€‘term taste captured via aggregated review & demographic embeddings. |
| **Latencyâ€‘friendly** | IVFâ€‘HNSW indexÂ + neighbour caching â†’ subâ€‘second inference per user. |
| **Plugâ€‘andâ€‘play** | Swap any sentenceâ€‘encoder or LLM via simple YAML. |
| **Multimodal ready** | Dropâ€‘in CLIP / ViT image embeddings for richer item features. |



## ğŸ”° Baseline: STAR in a Nutshell
The original **S**imple **T**rainingâ€‘free **A**pproach for **R**ecommendation (STAR)consists of two stages:
1. **Retrieval** â€“â€¯semantic item embeddings (Gecko) + collaborative coâ€‘occurrence scores â†’ topâ€‘K candidates.  
2. **Ranking** â€“â€¯an LLM (GeminiÂ 1.5Â Flash) reâ€‘orders those candidates via pairâ€‘wise slidingâ€‘window prompts.
<p align="center">
  <img src="Image/Original.png" width="720" alt="Baseline STAR pipeline">
</p>

STAR already outperforms several fullyâ€‘trained recommenders while requiring zero training.


## ğŸš€Â What STAR+ Adds

| Upgrade | Description |
|---------|-------------|
| **User Persona Embedding** | Dense vector from a userâ€™s review text & demographics, added to interactionâ€‘based user vector. |
| **Multimodal Embedding** | Optional CLIP / ViT support for product images. |
| **Fast FAISS Retrieval** | Bruteâ€‘force â†’ IVFâ€‘HNSWÂ + neighbour cache â†’Â â‰ˆ60â€¯% latency drop. |
| **Adaptive Score Fusion** | Perâ€‘user weight \(a_u\); zâ€‘score normalisation; recencyâ€‘aware decay. |
| **Promptâ€‘Tuned LLM Ranking** | Inject topâ€‘3 â€œhelpfulâ€ reviews per item & ask for Bordaâ€‘count score. |

> **Bottom line:** STAR+ keeps STARâ€™s simplicity yet gains **+0.011 NDCG@10**, **+0.015 HR@10**, **+0.011 NDCG@10** and **+0.002 HR@10** and trims inference **â€‘35â€¯%**.


## ğŸ† Detailed Results
<p align="center">
  <img src="Image/Results.png" width="560" alt="STAR+ results">
</p>


## ğŸ“‚Â Dataset
For this project, we utilize the [Amazon Reviews dataset](https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews), the same corpus adopted in the original STAR paper.


## âš™ï¸Â Pipeline Overview

### 1ï¸âƒ£ Data Process
After downloading the data, you can run following code to process data and generate the train test data. Since our recommendation system do not need training, we do not need valid dataset here. We also filter items that have no history and meta data to improve efficiency.
```bash
python data_processing\process_data.py
python data_processing\generate_train_test.py
python data_processing\filter_item_meta.py
```

### 2ï¸âƒ£ Construct Matrices
semantic item embeddings (Gecko) + collaborative coâ€‘occurrence scores + User embedding
```bash
python construct_matrices\construct_collaborative.py
python construct_matrices\embedding.py
python construct_matrices\user_embedding.py
``` 

## 3ï¸âƒ£ Retrival Results and Evaluation
```bash
python retrival.py
python retrival_experiment.py
```

## 4ï¸âƒ£ Ranking Results and Evaluation
```bash
python rank_prompt_generation.py
python ranking.py
python evaluate_rank.py
```

## 5ï¸âƒ£ Other experiments
```bash
python Optional\embedding_multimodal.py
python Optional\get_neighbor_item.py
python Optional\rank_prompt_engineer.py
```



